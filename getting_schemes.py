# -*- coding: utf-8 -*-
"""Getting Schemes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15l4sob5Xkq3S6rh5T9AZvFUX-Ly0utdA
"""
# import keras_nlp
# import seaborn as sns
# from transformers import BertTokenizer
import pandas as pd
from tqdm import tqdm
import string
tqdm.pandas()
import numpy as np
from sentence_transformers import SentenceTransformer, util
import matplotlib.pyplot as plt
import nltk
from nltk.corpus import stopwords
import string
import numpy as np
from dotenv import load_dotenv
import os
from sklearn.metrics.pairwise import cosine_similarity
import tensorflow as tf
import pickle
from flask import Flask, request, jsonify
from flask import Flask,jsonify
import json
"""**IMPORTING PKL FILE OF EDITED CSV**

A column(embeddings) which was MiniLM embedding of information
"""
file_path = os.path.join(os.path.dirname(__file__),'getting_schemes_with_id.pkl')

# Ensure the file exists before attempting to load
if os.path.exists(file_path):
    df = pd.read_pickle(file_path)
else:
    raise FileNotFoundError(f"File not found at {file_path}")
# df = pd.read_pickle(r"./ML-model/src/embeddings_final.pkl")

import ast

model = SentenceTransformer('all-MiniLM-L6-v2')

text="i am  poor farmer"

sentence_emb = model.encode([text], convert_to_tensor=True)

def compare(sentence_emb,scheme_embedding):
  sentence_embedding_2d = sentence_emb.numpy().reshape(1, -1)
  scheme_embedding_2d = scheme_embedding.numpy().reshape(1, -1)
  # Calculate the cosine similarity
  similarity = cosine_similarity(sentence_embedding_2d, scheme_embedding_2d)
  return similarity.item()

def get_top_k(df, sentence_emb, compare_fn, emb_col="embeddings", k=5):
    # Apply the compare function to each embedding in the column
    df = df.copy()  # avoid modifying original
    df["similarity"] = df[emb_col].apply(lambda emb: compare_fn(sentence_emb, emb))
    # Sort by similarity in descending order
    top_k = df.sort_values("similarity", ascending=False).head(k)
    return top_k

get_top_k(df, sentence_emb,compare, emb_col="embeddings", k=5)

def get_schemes(sentence_emb,df):
  return get_top_k(df, sentence_emb,compare, emb_col="embeddings", k=5)

data=get_schemes(sentence_emb,df)

output=data[["scheme_name","details","benefits","schemeCategory"]]

output

null_embeddings_indices = df[df['embeddings'].isnull()].index.tolist()

null_embeddings_indices
# def get_api_response(text):
#   import google.generativeai as genai
#   genai.configure(api_key)
#   model = genai.GenerativeModel("gemini-2.5-flash")
#   response=model.generate_content(f"""
#   this dataset have just 5 rows, display the schemes, followed by corresponding details, benefits,and documents required
#   {output}
#   only the info of this data should be given as output, nothing else
#   make it look easy to read for a normal person, make sure the output is in a json format
#   and the keys should be scheme_name, details, benefits, schemeCategory. nothing else should be there in the output
#   """)
#   return response.text

app = Flask(__name__)

@app.route('/submit', methods=['POST'])
def submit_data():
    data = request.get_json()   # Get JSON data from request body
    prompt = data.get('prompt')  # Extract 'name' field
    sentence_emb = model.encode([prompt], convert_to_tensor=True)
    data2 = get_schemes(sentence_emb, df)
    output = data2[["scheme_id"]]
    return output.to_json(orient='records', force_ascii=False)

# Load environment variables from .env file
load_dotenv()

if __name__ == "__main__":
    port_= int(os.environ.get("PORT",5000)) 
    app.run(debug=True,host="0.0.0.0",port=port_)
